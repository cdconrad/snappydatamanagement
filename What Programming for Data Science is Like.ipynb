{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f8a6ea",
   "metadata": {},
   "source": [
    "# What Programming for Data Science is Like\n",
    "*Â© 2023 Colin Conrad*\n",
    "\n",
    "This exercise, along with the other two exercises, are designed to give you some hands-on experience with data science. The approach that we will take is a lot more technical than in the previous chapters. These exercises will require you to use programming languages. Though you are not expected to have any formal training in computer programming, having a foundation in programming will help you a lot to understand what is going on.\n",
    "\n",
    "The tools we will use are built in the Python programming language, one of the most commonly used tools in data science.\n",
    "\n",
    "**This notebook, we will achieve the following objectives:**\n",
    "- Run `hello world`, a basic Python script\n",
    "- Assign Python variables\n",
    "- Perform basic string manipulation\n",
    "- Turn a csv dataset into a dataframe and build a simple query\n",
    "- Create an advanced query\n",
    "- Collect descriptive statistics from your dataframe\n",
    "- Make changes to your dataframe\n",
    "- Visualize the price of Airbnb around the University of Toronto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1290ad",
   "metadata": {},
   "source": [
    "## 1. Run basic Python scripts\n",
    "As you know by now, Python is a high level programming language designed to emphasize readability. There are many reasons why someone might want to use Python, though the main reasons why we have opted to use Python in this course is that it has an extensive list of data science libraries. In fact, you are likely currently using Anaconda, a set of Python tools designed specifically for our use case. \n",
    "\n",
    "Traditionally, the very first thing that people do when learning a new programming language is learn how to print `hello world!`. In Python, this is really straight forward. Try running the following code by selecting the cell and clicking `Run` (alternatively, you can select `shift + enter`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef969e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints 'hello world!'\n",
    "print('hello world!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca28bb7",
   "metadata": {},
   "source": [
    "Congratulations, you probably just run your first Python script! This is a bigger accomplishment than you might think. You have taken your first steps into the wonderful world of code.\n",
    "\n",
    "Let's break down the concepts above a bit. First, you probably see the `#prints 'hello world!'` bit at the top. This is a comment. Comments are cool because they describe the code that you are executing, without themselves being executed. These are an essential part of writing good code because they tell other readers what the code does. It might seem silly at first, but once you start collaborating with other people you *will* understand the value of comments.\n",
    "\n",
    "The second thing worth discussing is the `print('hello world!')` bit. Python's `print()` function is a default function in Python which prints the string contained within the parentheses in the console. This is super handy when trying to debug code, and serves as a great starting point for our tutorial.\n",
    "\n",
    "Another majoir difference between this exercise and past exercises is that we are using a notebook. Notebooks are increasingly popular among researchers and data scientists. In fact, I feel comfortable saying that it is _an essential tool_ for doing data science work. Without tools like Jupyter, we will create mess; replicable science needs *documentation*. Using Jupyter, we are able to effectively share code, but perhaps more importantly, to describe it. In many ways, the art of documentation is a subject in its own right, which we will touch on throughout this course.\n",
    "\n",
    "Jupyter notebooks are divided into a series of cells, which each contain code that can be written and transferred however you would like. You have already created and executed a cell above, when you ran your first Python code. What is less obvious is that even this text is written in a cell! **Try double-clicking on this cell to see its code**. The difference between this cell and the previous is that this cell consists of documentation code, rather than Python.\n",
    "\n",
    "By default, Jupyter notebooks support creating documentation using a type of code called *Markdown*. Unlike Python, which is designed to process logic, Markdown is designed to facilitate the creation of text. In other words, Markdown is not a programming language; rather it is a *markup language*. More specifically, Markdown is a derivative of the hypertext markup language (a.k.a. HTML) and builds on HTML's fundamentals. If you have ever taken an introduction to webpage design course, markdown will be very familiar to you; you can even create markdown text using HTML code!\n",
    "\n",
    "We will not get into the details on how to create markdown files today, though we will slowly build this skill up as we make out way through the course. For now, the most important things that you need to know are that:\n",
    "\n",
    "1. You can specify the type of code that each cell belongs to using the dropdown box immediately to the right of the `Run` button.\n",
    "2. You can modify Markdown cells much like Python cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe60f0eb",
   "metadata": {},
   "source": [
    "## 2. Assign Python variables\n",
    "Like an Excel spreadsheet, programming languages can store data in the form of variables. In Python, variables can consist of many different types of data--integers, strings, floats, and more complex data structures such as lists and dictionaries. Using data stored in variables, we can create code that does virtually anything that we can imagine!\n",
    "\n",
    "Building on the main theme of this book, let's learn by doing. Last year, there were 122 people registered for my undergraudate data management class. If we wanted to save this number in a variable we could write the following Python code. Try running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec937862",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment = 122"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971c8fa1",
   "metadata": {},
   "source": [
    "Great work! Python has now saved a variable called `enrollment` and knows that its value is the interger `122`. Try running the code below to see if Python remembers the number of people enrolled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb45928",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128be052",
   "metadata": {},
   "source": [
    "This is good. However, this example is only somewhat accurate. Many students in my classes do not join us in person, and for various reasons can only join us online. If we wanted to store this data properly, we might want to create three variables: one containing the in person enrollment, one containing the online enrollment, and one containing the total enrollment. Let's try expressing them using the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_person_enrollment = 88 # the number who took the course in-person\n",
    "\n",
    "online_enrollment  = 34 # the number who attended remotely\n",
    "\n",
    "total_enrollment = in_person_enrollment + online_enrollment # the total number attending the course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24027dac",
   "metadata": {},
   "source": [
    "Finally, if we wanted to retrieve any of these variables, you can do so any time in Jupyter. For exmaple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_person_enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2001c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_enrollment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16417f4d",
   "metadata": {},
   "source": [
    "## 3. Perform basic string manipulation\n",
    "One of the most interesting features of Python is the way that strings are stored. As mentioned earlier, strings consist of a series of characters that are often stored in a variable. Python has a number of default features that make it easy to change strings to suit our needs. For instance, Python treats strings as a series of elements (often called an 'array') which makes it easy to break them apart. If we wanted to retrieve the first character in the `course_title` string, we could easily retrieve it by using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ac819",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_title = \"2022 Working with Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e54574",
   "metadata": {},
   "source": [
    "This is a very handy feature for data scientists. You will often have to manage textual data and having the ability to easily separate strings will save you no only time, but also a great deal of grief. Let's use a more concrete example. If we wanted to only retrieve the course year in the `course_title` string, we could create a variable called `course_year` which consists of only the first four characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf97b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_year = course_title[0:4] #retrieves the first four characters in the course_title string\n",
    "\n",
    "course_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18874290",
   "metadata": {},
   "source": [
    "Python also comes with a number of default functions designed for string manupulation. We have already seen the `print()` function, which is one such example. Print typically prints the string values that are contained in the function's parentheses. Another handy function is `len()`, which gives us the length of a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d919c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(course_year) #specifies the number of characters in the string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1dd35a",
   "metadata": {},
   "source": [
    "Another handy feature of Python is that strings can be easily concatenated. In Python, we can concatenate strings by simply using the `+` character. If we wanted to add the name of the course to the course title, we can easily do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efd9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_title = course_title + \": Data Managmeent for Business and Social Science students (of all scholarly stripes)\" #adds the name to the course title\n",
    "\n",
    "print(course_title) #prints the new course title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c88b6b",
   "metadata": {},
   "source": [
    "# 4. Turn your dataset into a dataframe and build a simple query\n",
    "\n",
    "With this, you probably understand the basics. Let's do something a little more fun. One of the great things about Python is that it contains thousands of _libraries_ that are maintained by open source contributors. Libraries make our lives easier because they provide additional functionality that would take years to develop on our own. Throughout the rest of this exercise, we will use `Pandas` one of the most common Python data frame libraries, which is very often used by data scientists. \n",
    "\n",
    "The [Pandas](https://pandas.pydata.org/docs/getting_started/index.html#getting-started) dataframe is a data structure, sort of liek a spreadsheet but much more complex, which makes it easier to navigate and analyze large datasets. Built upon numpy and other dependencies, this tool is among the most essential resources for conducting analysis on larger datasets. Like basic Python, we will use this tool in nearly all subsequent exercises, so be sure to watch this one closely.\n",
    "\n",
    "Helpful reading: [10 minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)\n",
    "\n",
    "It's also important to note that `pandas` is a framework built on top of the `numpy` library, which was originally designed to make data science easier. Numpy is a tool for transforming your data into a multi-dimensional array, sort of like a hyper-efficient spreadsheet. It's not great to use in its raw form unless you are interested in going deep into machine learning. Pandas transforms our data into numerical tables (a.k.a. data frames) which are easier to calculate and sort through.\n",
    "\n",
    "Let's return to the Airbnb data originally explored in Chapter 6, only this time, we will explore Toronto, a much bigger city. To transform a csv file into a pandas object we need to import the pandas library. We can then import a csv file by using pandas' built-in read_csv feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # import pandas \n",
    "\n",
    "import numpy as np # import numpy; it's usually a good practice to import this as well\n",
    "\n",
    "import matplotlib.pyplot as plt # we will use this to visualize later\n",
    "\n",
    "tor = pd.read_csv('data/9_toronto_listings.csv') # command pandas to import the data; isn't this easier than the csv library?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffbb48f",
   "metadata": {},
   "source": [
    "### Dataframe head\n",
    "Once our data frame has been imported we can apply a few methods that can generate knowledge about the dataset. The `head()` method gives us a summary of the first five items in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edf4321",
   "metadata": {},
   "outputs": [],
   "source": [
    "tor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b99f04",
   "metadata": {},
   "source": [
    "### Dataframe series\n",
    "\n",
    "Data frames are easily navigable compared to lists or dictionaries. If we want to retrieve all of the data from a column in the dataframe, we can call that column similarly to calling a method. The code below will give us the values for `neighbourhood` from the whole dataset, but will give us only the first and last values when printed. This is super-handy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac49f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tor.neighbourhood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77774b47",
   "metadata": {},
   "source": [
    "### A transposed dataframe\n",
    "\n",
    "Some things that are somewhat cumbersome with lists and dictionaries are also very simple with pandas. For instance, if we wish to transpose our data (make the rows columns and the columns rows) we can use the `.T` method. This can be helpful when making calculations across entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tor.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bf4696",
   "metadata": {},
   "source": [
    "### Sort values\n",
    "In addition, dataframes can be easily sorted. These sorting features are similar to SQL (_Structured Query Language_) which many of you will be familiar with. The following code will sort the data by price starting with the highest values. \n",
    "\n",
    "I wonder who seriously believes that they can rent an apartment for $13 437 per night?! It must be fancy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce80646",
   "metadata": {},
   "outputs": [],
   "source": [
    "tor.sort_values(by='price', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bdac32",
   "metadata": {},
   "source": [
    "# 5. Create an advanced query\n",
    "## Subsetting the data\n",
    "Dataframes are for a lot more than performing large observations. Perhaps the coolest feature of a dataframe is that it facilitates efficient queries and to retrieve subsets of the data. In pandas, a subset is declared by writing square brackets following the data frame-- for instance, `tor['neighbourhood']` would return the values of neighborhood. However, we can also use this to conduct Boolean searches as well. For instance, if we wanted to retrieve only the values where `neighbourhood_group == University` we could write a query as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ccd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tor[tor.neighbourhood == 'University']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14cec0b",
   "metadata": {},
   "source": [
    "### Sorting subsets\n",
    "\n",
    "Similarly, to before, if we wanted to list the values from the area around the University of Tornto according to price, we can create a new data frame which is equal to this subset and sort it by price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f8d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "university = tor[tor.neighbourhood == 'University']\n",
    "\n",
    "university.sort_values(by='price', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f00e331",
   "metadata": {},
   "source": [
    "### Query using two conditions\n",
    "\n",
    "Queries can also be more complex. If we wish to choose a subset of data which is constrained by two conditions, we can include both conditions by using the `&` operator. The following query will retrieve the values that match `University` which also have a `last_review` equal to `2023-06-04`, the date closest to when I retrieved this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a9e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_university = tor[(tor.neighbourhood == 'University') & \n",
    "                      (tor.last_review == '2023-06-04')]\n",
    "\n",
    "recent_university.sort_values(by='price', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a098dc1b",
   "metadata": {},
   "source": [
    "# 6. Collect descriptive statistics from your dataframe\n",
    "One of the most handy features of pandas dataframes is that they come with a few built-in methods for conducting descriptive analysis. For example, the `.describe()` method will give summary of statistical measures of a given dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tor.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823e2316",
   "metadata": {},
   "source": [
    "### Describe a column\n",
    "This is good, but perhaps too much to be useful. Instead, we could choose to apply `.describe()` to a single column. This will give us more manageable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a2404",
   "metadata": {},
   "outputs": [],
   "source": [
    "tor.price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc4744e",
   "metadata": {},
   "source": [
    "### Calculate the mean price\n",
    "In addition, dataframes also have functions for calculating specific statistics such as mean, median and mode. To calculate the mean value of a column we can write the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aae5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tor.price.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a9ce2",
   "metadata": {},
   "source": [
    "### Calculate the sum\n",
    "Alternatively, if we wanted to find the sum of a column (e.g. the total number of reviews) we can use the sum function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a8312",
   "metadata": {},
   "outputs": [],
   "source": [
    "tor.number_of_reviews.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624105d0",
   "metadata": {},
   "source": [
    "### Calculate number of unique values\n",
    "Finally, there are a few other methods which are handy. For instance, the `.nunique()` method will tell use the number of unique values in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tor.host_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f00b8",
   "metadata": {},
   "source": [
    "# 7. Make changes to your dataframe\n",
    "In addition to being navigable, dataframes are also relatively easy to change. For instance, if we wanted to insert a column, we could use the `.insert()` method. According to the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.insert.html), this method requires four pieces of information: \n",
    "- Where to insert it\n",
    "- The name of the column\n",
    "- The value to be inserted\n",
    "- Whether to allow duplicates\n",
    "\n",
    "The code below inserts the value \"Airbnb\" in a column named `dataset`. This would be handy if we acquired our data from more than one source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "tor.insert(2, \"dataset\", \"Airbnb\", True)\n",
    "tor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41352f1",
   "metadata": {},
   "source": [
    "### Deleting data in python\n",
    "This said, given that our data came from a single source, we have no need for this. To drop a column, we could choose to use the del keyword, which deletes objects stored in python. Note that this keyword is not unique to pandas and can be used for virtually anything in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13df316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tor['dataset']\n",
    "tor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87282f72",
   "metadata": {},
   "source": [
    "### The drop method\n",
    "The proper way to drop a column in pandas however is to use the `.drop()` method. This method is used to drop rows or columns from a pandas dataframe. For instance, if we wished to drop the first entry we could use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed09e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_tor = tor.drop([0, 1]) # create a new dataframe which has the first two values dropped\n",
    "\n",
    "mod_tor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab92c3a",
   "metadata": {},
   "source": [
    "Pandas drops rows by default so we only needed to provide the indexes to make it happen. Alternatively, to drop columns we need to provide a label and an `axis=1` value to tell pandas to search for the column with said label. If we wished to remove the host names (say, in order to better preserve privacy) we could specify the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_tor = tor.drop(labels='host_name', axis=1) # create a new dataframe which has the first two values dropped\n",
    "\n",
    "mod_tor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec313209",
   "metadata": {},
   "source": [
    "### Entering new columns\n",
    "We can also add new columns to our dataframe. To create a new column, you can add the column values using a key/value format. The code below creates a new column called `reviews_to_avaliability_ratio` which calculates the number of reviews relative to the listing availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9af311",
   "metadata": {},
   "outputs": [],
   "source": [
    "tor['reviews_to_avaliability_ratio'] = tor['number_of_reviews']/tor['availability_365']\n",
    "\n",
    "tor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39f925",
   "metadata": {},
   "source": [
    "# 8. Visually compare apartment types\n",
    "Finally, we are now ready to visualize the data. Pandas dataframes have built-in functions for conducting visualizations that leverage a popular data visualization library callend `matplotlib`. We will explore this library in more detail in other exercises, but I wanted to conclude this chapter's exercise by giving you a taste of what it can do. In this case, we may wish to find which room types have good deals. Let's return to the `university` segment.\n",
    "\n",
    "To create an effective visualization, we may wish to simplify our data, such as by calculating the median value of each room type. Fortunately, Pandas has the `groupby` function. We can use this to calculate the median values and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c4898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "university_rooms = university.groupby(\"room_type\") # group by room_type\n",
    "\n",
    "university_rooms['price'].median().plot.bar(figsize=(12,6)) # calculates medians, plots the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e398d",
   "metadata": {},
   "source": [
    "## Conclusion and credit exercises\n",
    "Programming is tricker than using pre-built software, but it gives a lot of flexibility. Though getting to the point where we create simple visualizations seems underwhelming, especially when compared to our previous exercises with Tableau, this exercise demonstrates how it is doable. If anything, I hope you can appreciate how data scientists spend their days.\n",
    "\n",
    "In the subsequent exercises we will build on these skills to demonstrate two core functions of data science: statistical analysis and machine learning. These exercises will also leverage the Jupyter notebook format to demonstrate the skills.\n",
    "\n",
    "If you are completing this exercise as part of a course, please see your learning management system for the graded exercise questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
